![image-20210916232409633](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210916232409633.png)

## Spark 入门

> Spark是一个基于内存的快速，通用，可扩展的大数据分析计算引擎。

### 1.1 基本介绍

#### 1.1.1 Spark和Hadoop对比

1、Hadoop的MapReduce是大家熟悉的计算框架，那么为什么我们要学习新的计算框架Spark？

- MapReduce的设计相对比较简单，map进行数据切分，reduce将切分后的数据进行计算并输出到磁盘中，下一次使用还需要从磁盘中读取，这样磁盘IO就比较多，在多并行运行的数据可复用场景中并不是很适合使用，比如机器学习，图挖掘算法，交互式数据挖掘算法。
- Spark 是一个分布式数据快速分析项目。它的核心技术是弹性分布式数据集（Resilient Distributed Datasets），提供了比 MapReduce 丰富的模型，可以快速在内存中对数据集进行多次迭代，来支持复杂的数据挖掘算法和图形计算算法。

根本差异：多个job之间的数据通信问题，Spark多个作业之间数据通信是基于内存的，而hadoop是基于磁盘的。

2、那么为什么还使用hadoop？

我们可以看出在绝大多数的数据计算场景中，Spark 确实会比 MapReduce更有优势。但是 Spark 是基于内存的，所以在实际的生产环境中，由于内存的限制，可能会由于内存资源不够导致 Job 执行失败，此时，MapReduce 其实是一个更好的选择，所以 Spark并不能完全替代 MR。

3 核心模块

![image-20210916234113802](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210916234113802.png)



### 1.2 Spark运行环境

#### 1.2.1 本地环境

所谓的 Local 模式，就是不需要其他任何节点资源就可以在本地执行 Spark 代码的环境，一般用于教学，调试，演示等。

1、local环境的wordcount

![image-20210921214726507](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210921214726507.png)

2、退出本地模式

```shell
:quit或者ctrl+c
```

3、提交应用

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master local[2] \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

- class 表示要执行程序的主类，此处可以更换为咱们自己写的应用程序
- master local[2] 部署模式，默认为本地模式，数字表示分配的虚拟 CPU 核数量
- spark-examples_2.12-3.0.0.jar 运行的应用类所在的 jar 包，实际使用时，可以设定为咱
  们自己打的 jar 包
- 数字 10 表示程序的入口参数，用于设定当前应用的任务数量

#### 1.2.2 Standalone模式

实工作中还是要将应用提交到对应的集群中去执行，这里我们来看看只使用 Spark 自身节点运行的集群模式，也就是我们所谓的独立部署（Standalone）模式。Spark 的 Standalone 模式体现了经典的 master-slave 模式。

集群规划:

|       | hadoop02      | hadoop03 | hadoop04 |
| ----- | ------------- | -------- | -------- |
| Spark | Worker+master | Worker   | Worker   |

1、安装spark到指定机器

2、修改配置文件

```shell
mv slaves.template slaves
vim slaves
```

![image-20210921215958981](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210921215958981.png)

3、修改`spark-env.sh.template`文件名字

```shell
mv spark-env.sh.template spark-env.sh
```

4、修改`spark-env.sh`文件

添加JAVA_HOME环境变量以及集群对应的master节点信息

```shell
export JAVA_HOME=/opt/module/jdk1.8
SPARK_MASTER_HOST=hadoop02
SPARK_MASTER_PORT=7077
```

注：7077 端口，相当于 hadoop3 内部通信的 8020 端口，此处的端口需要确认自己的 Hadoop配置

5、分发配置信息到其他的节点

```shell
[code1997@hadoop02 spark-3.0.0]$ xsync conf/*
```

6、启动集群

```shell
[code1997@hadoop02 spark-3.0.0]$ sbin/start-all.sh
```

![image-20210921220827212](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210921220827212.png)

查看状态：

```shell
[code1997@hadoop02 spark-3.0.0]$ jps
2594 Worker
2666 Jps
2511 Master

[code1997@hadoop03 module]$ jps
2067 Worker
2139 Jps

[code1997@hadoop04 module]$ jps
2036 Jps
1964 Worker
```

7、访问master的web UI

url：http://192.168.134.142:8080/

![image-20210921221107045](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210921221107045.png)

8、提交应用

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://hadoop02:7077 \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

#### 1.2.3 配置历史服务器

由于 spark-shell 停止掉后，集群监控 hadoop02:4040 页面就看不到历史任务的运行情况，所以开发时都配置历史服务器记录任务运行情况。

1、改`spark-defaults.conf.template` 文件名为 `spark-defaults.conf`

2、配置日志存储路径

编配`spark-defaults.conf`

```shell
spark.master                     spark://hadoop02:7077
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://hadoop02:9000/spark/history-logs/
spark.serializer                 org.apache.spark.serializer.KryoSerializer
spark.driver.memory              3g
spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
```

注1：`spark.eventLog.dir`的文件夹地址要事先存在。

```shell
[code1997@hadoop02 hadoop-2.7.2]$ sbin/start-dfs.sh
[code1997@hadoop02 hadoop-2.7.2]$ hdfs dfs -mkdir -p /spark/history-logs/
```

注2：不同版本的hadoop的hdfs端口可能不一样

可以查看Hadoop的核心配置文件`core-site.xml`

```
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop02:9000</value>
    </property>
```

3、修改 `spark-env.sh`，添加日志配置。

```shell
export SPARK_HISTORY_OPTS="
-Dspark.history.ui.port=18080
-Dspark.history.fs.logDirectory=hdfs://hadoop02:9000/spark/history-logs/
-Dspark.history.retainedApplications=30"
```

- 参数 1 含义：WEB UI 访问的端口号为 18080
- 参数 2 含义：指定历史服务器日志存储路径
- 参数 3 含义：指定保存 Application 历史记录的个数，如果超过这个值，旧的应用程序信息将被删除，这个是内存中的应用数，而不是页面上显示的应用数。

4、分发配置信息

```shell
[code1997@hadoop02 spark-3.0.0]$ xsync conf/
```

5、启动集群和历史服务

```shell
[code1997@hadoop02 spark-3.0.0]$ sbin/start-all.sh
[code1997@hadoop02 spark-3.0.0]$ sbin/start-history-server.sh
```

6、重新执行任务

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://hadoop02:7077 \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

7、查看历史服务

url：http://192.168.134.142:18080/

![image-20210921225135932](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210921225135932.png)

#### 1.2.4 配置高可用(HA)

所谓的高可用是因为当前集群中的 Master 节点只有一个，所以会存在单点故障问题。所以为了解决单点故障问题，需要在集群中配置多个 Master 节点，一旦处于活动状态的 Master发生故障时，由备用 Master 提供服务，保证作业可以继续执行。这里的高可用一般采用Zookeeper 设置：

集群规划：

|       | hadoop02                | hadoop03                | hadoop03         |
| ----- | ----------------------- | ----------------------- | ---------------- |
| Spark | Master+Zookeeper+Worker | Master+Zookeeper+Worker | Zookeeper+Worker |

1、启动`zookeeper`

2、修改`spark-env.sh`

```shell
export JAVA_HOME=/opt/module/jdk1.8
#注释配置
#SPARK_MASTER_HOST=hadoop02
#SPARK_MASTER_PORT=7077
#添加如下内容：修改webui端口，防止默认的8080被占用
SPARK_MASTER_WEBUI_PORT=8989
export SPARK_DAEMON_JAVA_OPTS="
-Dspark.deploy.recoveryMode=ZOOKEEPER
-Dspark.deploy.zookeeper.url=hadoop02,hadoop03,hadoop04
-Dspark.deploy.zookeeper.dir=/spark"
```

3、分发配置文件

4、启动集群

```shell
[code1997@hadoop02 spark-3.0.0]$ zk.sh start
[code1997@hadoop02 spark-3.0.0]$ sbin/start-all.sh
```

注：需要启动zk

![image-20210921230500332](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210921230500332.png)

5、启动hadoop03的master节点

```shell
[code1997@hadoop03 sbin]$ ./start-master.sh
starting org.apache.spark.deploy.master.Master, logging to /opt/module/spark-3.0.0/logs/spark-code1997-org.apache.spark.deploy.master.Master-1-hadoop03.out
```

![image-20210921231216735](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210921231216735.png)

6、提交应用到高可用集群

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://hadoop02:7077,hadoop03:7077 \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

7、停止hadoop02的master进程

```shell
[code1997@hadoop02 jars]$ jps
7635 Worker
7846 CoarseGrainedExecutorBackend
5191 NameNode
5335 DataNode
6680 HistoryServer
6890 QuorumPeerMain
7914 Jps
7771 SparkSubmit
7533 Master
[code1997@hadoop02 jars]$ kill -9 7533
```

8、查看hadoop03的master资源监控UI

状态从：standby->alive

![image-20210921231456725](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210921231456725.png)

#### 1.2.5 yarn模式

独立部署（Standalone）模式由 Spark 自身提供计算资源，无需其他框架提供资源。这种方式降低了和其他第三方资源框架的耦合性，独立性非常强。但是你也要记住，Spark 主要是计算框架，而不是资源调度框架，所以本身提供的资源调度并不是它的强项，所以还是和其他专业的资源调度框架集成会更靠谱一些。所以接下来我们来学习在强大的 Yarn 环境下 Spark 是如何工作的（其实是因为在国内工作中，Yarn 使用的非常多）。

1、解压文件到各个节点

2、修改hadoop配置`yarn-site.xml`文件，并分发到各个节点

```xml
    <!--是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是 true -->
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
    </property>
    <!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是 true -->
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
```

3、修改`spark-env.sh`，并分发

```shell
[code1997@hadoop02 conf]$ mv spark-env.sh.template spark-env.sh
[code1997@hadoop02 conf]$ vim spark-env.sh

#修改内容
export JAVA_HOME=/opt/module/jdk1.8
YARN_CONF_DIR=/opt/module/hadoop-2.7.2/etc/hadoop
```

4、启动hdfs和yarn集群

```shell
[code1997@hadoop03 sbin]$ ./start-yarn.sh 
starting yarn daemons
starting resourcemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-code1997-resourcemanager-hadoop03.out
hadoop04: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-code1997-nodemanager-hadoop04.out
hadoop02: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-code1997-nodemanager-hadoop02.out
hadoop03: starting nodemanager, logging to /opt/module/hadoop-2.7.2/logs/yarn-code1997-nodemanager-hadoop03.out

[code1997@hadoop02 sbin]$ ./start-dfs.sh 
Starting namenodes on [hadoop02]
hadoop02: starting namenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-code1997-namenode-hadoop02.out
hadoop04: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-code1997-datanode-hadoop04.out
hadoop02: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-code1997-datanode-hadoop02.out
hadoop03: starting datanode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-code1997-datanode-hadoop03.out
Starting secondary namenodes [hadoop04]
hadoop04: starting secondarynamenode, logging to /opt/module/hadoop-2.7.2/logs/hadoop-code1997-secondarynamenode-hadoop04.out

```

5、提交应用

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode cluster \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

错误1：

```shell
21/09/21 23:33:35 INFO ipc.Client: Retrying connect to server: hadoop03/192.168.134.143:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
```

原因：可能是`resourcemanager`没有启动成功

```shell
[code1997@hadoop03 spark-3.0.0-yarn]$ jps
3904 QuorumPeerMain
6240 Jps
6116 NodeManager
```

解决：启动yarn的时候一定要在resourcemanager节点上启动，否则resourcemanager不会被启动起来。

6、查看信息信息

url: http://192.168.134.142:8088

![image-20210922000828471](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210922000828471.png)

#### 1.2.6 配置历史服务器-yarn

1、修改配置文件`spark-defaults.conf`

配置日志路径

```shell
[code1997@hadoop02 conf]$ mv spark-defaults.conf.template spark-defaults.conf
[code1997@hadoop02 conf]$ vim spark-defaults.conf

spark.eventLog.enabled true
spark.eventLog.dir hdfs://hadoop02:9000/spark-yarn/history-logs
spark.yarn.historyServer.address=hadoop02:18080
spark.history.ui.port=18080
```

注：文件夹`spark-yarn/history-logs`要提交创建好

2、修改`spark-env.sh`

添加日志配置

```shell
export SPARK_HISTORY_OPTS="
-Dspark.history.ui.port=18080
-Dspark.history.fs.logDirectory=hdfs://hadoop02:9000/spark-yarn/history-logs/
-Dspark.history.retainedApplications=60"
```

3、启动历史服务器

```shell
[code1997@hadoop02 spark-3.0.0-yarn]$ sbin/start-history-server.sh
starting org.apache.spark.deploy.history.HistoryServer, logging to /opt/module/spark-3.0.0-yarn/logs/spark-code1997-org.apache.spark.deploy.history.HistoryServer-1-hadoop02.out
[code1997@hadoop02 spark-3.0.0-yarn]$ jps
12961 Jps
12084 NameNode
12228 DataNode
12916 HistoryServer
11813 NodeManager
6890 QuorumPeerMain
```

4、提交应用

```shell
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode client \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

5、查看ui

history url:http://192.168.134.142:18080/

![image-20210922002056544](https://gitee.com/code1997/blog-image/raw/master/bigdata/image-20210922002056544.png)

#### 1.2.7 windows模式

Spark 非常暖心地提供了可以在 windows 系统下启动本地集群的方式，这样，在不使用虚拟机的情况下，也能学习 Spark 的基本使用。

1、解压文件到无中文无空格目录下

2、执行`spark-shell.cmd`，开启本地环境

3、测试过程参考其他模式

#### 1.2.8 模式对比

| 模式       | Spark 安装机器数 | 需启动的进程     | 所属者 | 应用场景 |
| ---------- | ---------------- | ---------------- | ------ | -------- |
| Local      | 1                | 无               | Spark  | 测试     |
| Standalone | 3                | Master 及 Worker | Spark  | 单独部署 |
| Yarn       | 1                | Yarn 及 HDFS     | Hadoop | 混合部署 |

常见端口号：

- Spark 查看当前 Spark-shell 运行任务情况端口号：4040（计算）
- Spark Master 内部通信服务端口号：7077
- Standalone 模式下，Spark Master Web 端口号：8080（资源）
- Spark 历史服务器端口号：18080
- Hadoop YARN 任务运行情况查看端口号：8088
